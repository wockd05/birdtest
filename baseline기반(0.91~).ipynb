{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAgitnOJlKDP"
   },
   "outputs": [],
   "source": [
    "#pip install --user albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMRa1QpklKDQ"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qWfsOfH9lKDQ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wi1Db2UrlKDR"
   },
   "source": [
    "## Hyperparameter Settting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A5o_GduKlKDR"
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 50,\n",
    "    'LEARNING_RATE': 2e-4,\n",
    "    'BATCH_SIZE': 8,\n",
    "    'SEED': 41\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_JXLd-NlKDR"
   },
   "source": [
    "## Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XM8vrB7ClKDR"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed) ##random module의 시드 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) #해시 함수의 랜덤성 제어, 자료구조 실행할 때 동일한 순서 고정\n",
    "    np.random.seed(seed) #numpy 랜덤 숫자 일정\n",
    "    torch.manual_seed(seed) # torch라이브러리에서 cpu 텐서 생성 랜덤 시드 고정\n",
    "    torch.cuda.manual_seed(seed) # cuda의 gpu텐서에 대한 시드 고정\n",
    "    torch.backends.cudnn.deterministic = True # 백엔드가 결정적 알고리즘만 사용하도록 고정\n",
    "    torch.backends.cudnn.benchmark = True # CuDNN이 여러 내부 휴리스틱을 사용하여 가장 빠른 알고리즘 동적으로 찾도록 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2dNDjRSlKDR"
   },
   "source": [
    "## Train & Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hp8-kPyqlKDR"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 로드 부분\n",
    "df = pd.read_csv('C:\\\\wockd\\\\ultra\\\\ultra\\\\retina\\\\train.csv')\n",
    "# 전체 데이터셋의 1/2만 사용\n",
    "df = df.sample(frac=0.5, random_state=CFG['SEED']).reset_index(drop=True)\n",
    "\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8H1QFAoMlKDR"
   },
   "source": [
    "## Label-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "drZTs2s-lKDS"
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder() # 라벨인코딩 /라벨(목표 변수)를 정수로 인코딩\n",
    "# train, label의 라벨인코딩 과정 진행\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "val['label'] = le.transform(val['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jATp5YV5lKDS"
   },
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "H_1G5kXolKDS"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "\n",
    "        # 라벨이 존재할 경우와 없는 경우 처리\n",
    "        label = self.label_list[index] if self.label_list is not None else -1  # 라벨이 없을 경우 -1 반환\n",
    "        return image, label  # 이미지와 라벨을 항상 반환\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "\n",
    "\n",
    "# Compose는 여러 변환을 연속적으로적용할 수 있게 해주는 함수. (IMG 사이즈 224로 설정되어 있음)\n",
    "# 이미지 크기조정, 정구화, 텐서로 변환 포함.\n",
    "'''\n",
    "Normalize(mean=0.485, 0.456, 0.406값은 각 채널별 평균)\n",
    "std=(0.229, 0.224, 0.225 값은 각 채널별 표준편차)\n",
    "max_pixel_value: 이미지의 최대 픽셀 값 (8비트의 경우 255가 최대값)\n",
    "always_apply= Ture: 변환이 데이터셋의 모든 이미지에 대해 항상 적용.\n",
    "p: 변환이 적용될 확률: (0~1 사이)\n",
    "대부분의 경우 always_apply=True로 하고 p를 조절해서 사용\n",
    "'''\n",
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()])\n",
    "\n",
    "## train데이터셋 설정 및 불러오기\n",
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "## val 데이터셋 설정 및 불러오기\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "# Test 데이터셋 설정 및 불러오기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['img_path', 'upscale_img_path', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)  # train 데이터프레임의 열 이름 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "tensor([10, 21,  5, 12, 21,  6,  3, 11], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "for imgs, labels in train_loader:\n",
    "    print(imgs.shape)  # 이미지의 형태 확인\n",
    "    print(labels)      # 라벨의 형태 확인\n",
    "    break  # 첫 번째 배치만 확인 후 종료\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([8, 3, 224, 224])\n",
      "Labels: tensor([10, 21,  5, 12, 21,  6,  3, 11], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로더에서 반환되는 데이터 확인\n",
    "for batch in train_loader:\n",
    "    imgs, labels = batch  # 리스트에서 imgs와 labels 추출\n",
    "    print(\"Images shape:\", imgs.shape)  # 이미지의 형태 확인\n",
    "    print(\"Labels:\", labels)              # 라벨의 형태 확인\n",
    "    break  # 첫 번째 배치만 확인 후 종료\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로더에서 반환되는 데이터 확인\n",
    "for batch in train_loader:\n",
    "    print(type(batch))  # 반환된 배치의 타입 확인\n",
    "    print(len(batch))   # 반환된 배치의 요소 수 확인\n",
    "    break  # 첫 번째 배치만 확인하고 종료\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adMNpPlHlKDS"
   },
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bLarDzSWlKDS"
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    #le.classes는 LabelEncoder가 학습한 후에 갖게되는 속성 (고유한 클래스 라벨들의 배열)\n",
    "    def __init__(self, num_classes=len(le.classes_)):\n",
    "        super(BaseModel, self).__init__()\n",
    "        # EfficientNet B0 아키텍처를 사용하여 사전 훈련된 백본 설정. 특성 추출기 역함\n",
    "        self.backbone = timm.create_model('timm/deit3_large_patch16_224.fb_in22k_ft_in1k', pretrained=True)\n",
    "        # 백본 모델의 출력을 받아 최종적으로 클래스 수에 맞는 출력을 생성하는 선형 분류기\n",
    "        self.classifier = nn.Linear(1000, num_classes) #기본 출력크기 1,000으로 정의\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x) #backbone을 거쳐 특성이 추출\n",
    "        x = self.classifier(x) # 분류기에 전달되어 최종 출력 생성\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9FHeuHf4lKDS"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device) # 모델을 해당 디바이스로 옮김(cpu, gpu)\n",
    "    criterion = nn.CrossEntropyLoss().to(device) # 손실함수 정의하고 해당 device로 옮김\n",
    "\n",
    "    # 성능 기록 초기화\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    # 설정한 하이퍼파라미터의 epochs만큼 반복\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train() #모델을 훈련모드로 설정\n",
    "        train_loss = []\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{CFG['EPOCHS']} 시작\")  # 추가된 출력\n",
    "\n",
    "        # 반복을 통해서 배치 단위로 이미지와 라벨을 가져옴\n",
    "        for i, (imgs, labels) in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n",
    "            imgs = imgs.float().to(device)  # 이미지를 실수형으로 변경한 후 device로 올림\n",
    "            labels = labels.long().to(device)  # 데이터 타입 long으로 변경한 후 device로 올림\n",
    "\n",
    "            optimizer.zero_grad()  # 이전 그레디언트가 누적될 가능성이 있으니 초기화\n",
    "\n",
    "            output = model(imgs)  # 모델의 이미지를 입력하여 출력을 얻음\n",
    "            loss = criterion(output, labels)  # 손실 함수를 통해 손실 값을 계산함.\n",
    "\n",
    "            loss.backward()  # 손실에 대한 그레디언트 계산\n",
    "            optimizer.step()  # 옵티마이저를 통해 모델의 가중치 업데이트\n",
    "\n",
    "            train_loss.append(loss.item())  # 현재 배치에 대한 손실 값을 train_loss 리스트에 추가\n",
    "\n",
    "        # 각 에포크마다 validation함수를 호출하여서 검증 세트에서 모델의 성능을 평가\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss) # 각 배치에서 계산된 모든 손실 값의 평균을 구함\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 Score : [{_val_score:.5f}]')\n",
    "\n",
    "        # scheduler이 설정되어 있다면 검증 성능에 따라 학습률을 조정\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        # 가장 좋은 성능을 보인 모델을 반환\n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval() # 평가모드\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    # 평가모드의 경우에는 gradient를 초기화하는 부분이 없음 (backward 필요없음. 오직 평가만!)\n",
    "    with torch.no_grad(): # 이 블록 내에서 그레디언트 계산을 중단하여, 필요하지 않은 메모리 사용을 줄이고 계산 속도 향상.\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.long().to(device)  # 데이터 타입 long으로 변경한 후 device로 올림 (int로 변경하였을 때, error 발생했음)\n",
    "\n",
    "            pred = model(imgs)\n",
    "\n",
    "            loss = criterion(pred, labels)\n",
    "\n",
    "            # pred는 모델이 반환한 예측값. 각 클래스에 대한 확률 또는 점수를 포함하는 텐서. argmax(1)은 각 샘플에 대해 가장 높은 점수를 가진 클래스의 인덱스를 찾아줌.\n",
    "            # detach()는 현재 계산 그래프로부터 이 텐서를 분리하여, 이후 연산이 그래프에 기록되지 않도록함. 메모리 사용량 줄임\n",
    "            # cpu()는 cpu로 옮김 (GPU에 있었다면)\n",
    "            # numpy()는 텐서를 numpy 배열로 변환\n",
    "            # tolist()는 numpy 배열을 파이썬 리스트로 변환\n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "\n",
    "            # 실제 라벨도 위와 동일한 과정 진행\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "        _val_loss = np.mean(val_loss)\n",
    "        # average = 'macro'는 F1점수를 계산할 때, 각 클래스에 대한 F1점수를 동일한 가중치로 평균내어 전체 클래스에 대한 평균 F1점수를 계산.\n",
    "        # 각 클래스의 샘플 크기와 관계없이 모든 클래스를 동등하게 취급. 이는 클래스 불균형이 있을 때 유용하며, 모든 클래스를 공평하게 평가하고자 할 때 사용.\n",
    "        _val_score = f1_score(true_labels, preds, average='macro')\n",
    "\n",
    "    return _val_loss, _val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm  # timm 라이브러리 임포트 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZntcmuSclKDS",
    "outputId": "9a42397e-3318-4042-947e-c3f25843d03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.78it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.70381] Val Loss : [0.57833] Val F1 Score : [0.85528]\n",
      "Epoch 2/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.80it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.33171] Val Loss : [0.45627] Val F1 Score : [0.87155]\n",
      "Epoch 3/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.89it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.26848] Val Loss : [0.62632] Val F1 Score : [0.84013]\n",
      "Epoch 4/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.81it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.19152] Val Loss : [0.60399] Val F1 Score : [0.84560]\n",
      "Epoch 5/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.85it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.15860] Val Loss : [0.59070] Val F1 Score : [0.86112]\n",
      "Epoch 6/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.83it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.04386] Val Loss : [0.47494] Val F1 Score : [0.88666]\n",
      "Epoch 7/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.84it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.01424] Val Loss : [0.39910] Val F1 Score : [0.91530]\n",
      "Epoch 8/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.86it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.00032] Val Loss : [0.40596] Val F1 Score : [0.91760]\n",
      "Epoch 9/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.85it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.00006] Val Loss : [0.41353] Val F1 Score : [0.91891]\n",
      "Epoch 10/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.85it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.00004] Val Loss : [0.42196] Val F1 Score : [0.91934]\n",
      "Epoch 11/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.77it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.00002] Val Loss : [0.43121] Val F1 Score : [0.91934]\n",
      "Epoch 12/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.83it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.00002] Val Loss : [0.44125] Val F1 Score : [0.91934]\n",
      "Epoch 13/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.79it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.00001] Val Loss : [0.45206] Val F1 Score : [0.91925]\n",
      "Epoch 14/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.95it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.00001] Val Loss : [0.45816] Val F1 Score : [0.91925]\n",
      "Epoch 15/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.82it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.00001] Val Loss : [0.46555] Val F1 Score : [0.92019]\n",
      "Epoch 16/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.94it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.00000] Val Loss : [0.47421] Val F1 Score : [0.92021]\n",
      "Epoch 17/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.90it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [0.00000] Val Loss : [0.48410] Val F1 Score : [0.92021]\n",
      "Epoch 18/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.93it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [0.00000] Val Loss : [0.49511] Val F1 Score : [0.92017]\n",
      "Epoch 19/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.90it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.00000] Val Loss : [0.50143] Val F1 Score : [0.92017]\n",
      "Epoch 20/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.95it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.00000] Val Loss : [0.50911] Val F1 Score : [0.92017]\n",
      "Epoch 21/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.08it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [0.00000] Val Loss : [0.51815] Val F1 Score : [0.92057]\n",
      "Epoch 22/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.07it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [0.00000] Val Loss : [0.52847] Val F1 Score : [0.92057]\n",
      "Epoch 23/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.12it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [0.00000] Val Loss : [0.53996] Val F1 Score : [0.92055]\n",
      "Epoch 24/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.11it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [0.00000] Val Loss : [0.55244] Val F1 Score : [0.92093]\n",
      "Epoch 25/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.07it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [0.00000] Val Loss : [0.56566] Val F1 Score : [0.92093]\n",
      "Epoch 26/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.05it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [0.00000] Val Loss : [0.57955] Val F1 Score : [0.92093]\n",
      "Epoch 27/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.75it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [0.00000] Val Loss : [0.59371] Val F1 Score : [0.92092]\n",
      "Epoch 28/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.97it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [0.00000] Val Loss : [0.60127] Val F1 Score : [0.92092]\n",
      "Epoch 29/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.88it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [0.00000] Val Loss : [0.60976] Val F1 Score : [0.92092]\n",
      "Epoch 30/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.97it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Train Loss : [0.00000] Val Loss : [0.61905] Val F1 Score : [0.92094]\n",
      "Epoch 31/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.01it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Train Loss : [0.00000] Val Loss : [0.62409] Val F1 Score : [0.92052]\n",
      "Epoch 32/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.99it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Train Loss : [0.00000] Val Loss : [0.62994] Val F1 Score : [0.92052]\n",
      "Epoch 33/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:28<00:00, 10.50it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], Train Loss : [0.00000] Val Loss : [0.63628] Val F1 Score : [0.92090]\n",
      "Epoch 34/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.94it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], Train Loss : [0.00000] Val Loss : [0.63971] Val F1 Score : [0.92090]\n",
      "Epoch 35/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.95it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], Train Loss : [0.00000] Val Loss : [0.64361] Val F1 Score : [0.92090]\n",
      "Epoch 36/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.14it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], Train Loss : [0.00000] Val Loss : [0.64780] Val F1 Score : [0.92089]\n",
      "Epoch 37/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.88it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Train Loss : [0.00000] Val Loss : [0.65006] Val F1 Score : [0.92049]\n",
      "Epoch 38/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.09it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38], Train Loss : [0.00000] Val Loss : [0.65252] Val F1 Score : [0.92049]\n",
      "Epoch 39/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.05it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39], Train Loss : [0.00000] Val Loss : [0.65516] Val F1 Score : [0.92047]\n",
      "Epoch 40/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.03it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40], Train Loss : [0.00000] Val Loss : [0.65647] Val F1 Score : [0.92047]\n",
      "Epoch 41/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 11.00it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Train Loss : [0.00000] Val Loss : [0.65794] Val F1 Score : [0.92047]\n",
      "Epoch 42/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.03it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42], Train Loss : [0.00000] Val Loss : [0.65948] Val F1 Score : [0.92047]\n",
      "Epoch 43/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.10it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43], Train Loss : [0.00000] Val Loss : [0.66025] Val F1 Score : [0.92047]\n",
      "Epoch 44/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.01it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44], Train Loss : [0.00000] Val Loss : [0.66106] Val F1 Score : [0.92047]\n",
      "Epoch 45/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.02it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Train Loss : [0.00000] Val Loss : [0.66191] Val F1 Score : [0.92047]\n",
      "Epoch 46/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.02it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Train Loss : [0.00000] Val Loss : [0.66232] Val F1 Score : [0.92047]\n",
      "Epoch 47/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.97it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47], Train Loss : [0.00000] Val Loss : [0.66274] Val F1 Score : [0.92047]\n",
      "Epoch 48/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.93it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48], Train Loss : [0.00000] Val Loss : [0.66317] Val F1 Score : [0.92047]\n",
      "Epoch 49/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.97it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49], Train Loss : [0.00000] Val Loss : [0.66336] Val F1 Score : [0.92047]\n",
      "Epoch 50/50 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:26<00:00, 11.07it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50], Train Loss : [0.00000] Val Loss : [0.66356] Val F1 Score : [0.92047]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel() # 모델은 basemodel 가져옴\n",
    "model.eval() #평가모드로 전환 (훈련모드가 아닌 평가모드를 불러온 이유가 뭐지?..)\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"]) # optimizer 'adam'으로 설정 / 학습률 위의 하이퍼파라미터\n",
    "\n",
    "#학습률을 동적으로 조정하는 스케줄러 설정. 검증 성능이 개선되지 않으면 학습률 감소.\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test['img_path'].values, label_list=None, transforms=test_transform)  # label_list=None으로 설정\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MS_JTYgTlKDT",
    "outputId": "81715e20-7131-43b1-8f8b-b33c52ec5e6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 849/849 [01:18<00:00, 10.77it/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('C:\\\\wockd\\\\ultra\\\\ultra\\\\retina\\\\test.csv')\n",
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():  # gradient 초기화 없이 평가 진행\n",
    "        for imgs, _ in tqdm(test_loader):  # imgs와 labels를 언팩\n",
    "            imgs = imgs.to(device)  # 이미지를 device로 이동\n",
    "\n",
    "            pred = model(imgs)  # 모델에 이미지 입력\n",
    "\n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()  # 예측 결과 저장\n",
    "\n",
    "    preds = le.inverse_transform(preds)  # 라벨 인코딩 해제\n",
    "    return preds\n",
    "\n",
    "\n",
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9OvhX_KllKDT"
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('C:\\\\wockd\\\\ultra\\\\ultra\\\\retina\\\\sample_submission.csv')\n",
    "submit['label'] = preds\n",
    "submit.to_csv('good.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "newwoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
